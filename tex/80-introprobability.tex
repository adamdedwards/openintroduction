\chapter{Introduction to Probability Theory}
\markright{Chapter \ref{ch:introprobability}: Probability}
\label{ch:introprobability}
\setlength{\parindent}{1em}

\section{Evidential Support Revisited}

So far we've been talking about arguments that have an ``all or nothing'' relation of evidential support. These are deductive arguments. However, we noted in chapter~\ref{ch:basicevaluation} that not all arguments that we care about are deductive. Some arguments are inductive, meaning that their premises are not supposed to \emph{guarantee} their conclusion, but merely make it more likely. In this section we are going to make that notion more rigorously defined.

Recall that inductive arguments are intended to make their conclusions more likely. We can see that in the following argument:

\begin{earg}
\item[1.] Only one person wins the spelling bee.
\item[2.] There are 200 contestants in the spelling bee.
\item[3.] Sara is a contestant in the spelling bee.
\item[] \textcolor{white}{.}\sout{\hspace{.8\linewidth}}\textcolor{white}{.}
\item[$\therefore$] Sara will not win the spelling bee.
\end{earg}

You might react to this argument in a couple of ways. First, you might agree that the premises do make the conclusion more likely. If Sara is only one of 200 possible winners, it is not likely that Sara will win. The premises do support the conclusion that Sara will not win. However, you might also react to this argument by objecting: ``Hang on! Sara has been practicing for the spelling bee every day for months! She's definitely going to win!''

Both responses make sense and they both carry some implicit assumptions about Sara and about spelling bees. As we develop an understanding of probability we can make these assumption explicit.

\section{What is Probability?}\label{sec:whatisprob}

Before we go further into the chapter, let's get clear about what exactly we mean when we talk about probabilities. For many philosophers and statisticians, the best way to understand ``probability'' is a matter of substantial dispute. There are two popular ways of understanding probability.

\subsection{Degree of Truth}

One popular way to understand probability is as a representation of how true a given proposition is. As we said in chapter~\ref{ch:what_is_logic} the elements of logic are statements and statements can either be true or false. We can adjust our definition of ``statements'' to accommodate statements that may be somewhat true or somewhat false.

Another way to understand this interpretation is that probabilities represent the chance that something is true. When we flip a coin we often talk about the chance that the coin will land heads or land tails. So while it may seem strange to say that ``The coin will land heads.'' is \emph{somewhat true} and \emph{somewhat false} it is more natural to say that there is a chance that ``The coin will land heads.'' is true \emph{and} there is a chance that ``The coin will land heads.'' is false.

\subsection{Degree of Belief}

Another popular way to understand probability is as a representation of someone's degree of belief that a proposition is true. Perhaps talking about the degree of truth or the chance that some proposition is true seems too bizarre. ``Things are either true or false,'' the objection goes, ``Just because we don't know whether or not the coin will land heads doesn't mean that it's only half-true! It either happens or it doesn't.''

Instead of thinking of probabilities as representing the actual chance or degree to which a proposition is true, we can think of probabilities as representing how much \emph{we believe in each proposition.}

Either way we want to go, much of the formal machinery of probability will be the same. The philosophy of probability is concerned with identifying the best interpretation. Perhaps you have a sense right now of how you think that interpretation should go. Maybe you aren't sure yet. Either way, it will help to have a clear understanding of the formal methods of probability in order to think more clearly about the interpretation.

\section{Defining Probability}

We can think of probability as a function that maps propositions to a real number in the range $[0,1]$. This function is called a valuation function. Earlier, we gave a valuation function for propositions that mapped them to a binary number from the set $\{0,1\}$. Now we are imagining that propositions can take any value between zero and one (inclusive, meaning that the propositions can also take the values $0$ and $1$).

We will write the valuation function like this: $pr(\mvp)$ for any sentence in our language $\mvp$. The valuation function will then give us a value back that is between $0$ and $1$. When we use our valuation function we aren't talking about the content of the sentence directly, but indirectly by assigning it some value. However, it is important to note that almost no sentences involving metavariables will receive a valuation. Just like it doesn't make sense to ask whether $(\mvp\eand\mvq)$ is true or false without knowing what $\mvp$ and $\mvq$ stand for, we won't assign particular valuations to sentences like that either.

\section{Axioms of Probability}\label{sec:axiomsofprobability}

\citet{kolmogorov1933} first defined the axioms of probability in the form we now use. These axioms put some limits on how we can assign probabilities to the sentences in our language. The axioms are as follows:

\begin{description}
  \item[Axiom of Non-negativity] $\forall x \in X : pr(x) \ge 0$
  \item[Axiom of Normality] If $\{\}\vdash\mvp$, then $pr(\mvp)=1$
  \item[Axiom of Finite Additivity] If $\{\}\vdash\enot(\mvp\eand\mvq)$, then $pr(\mvp\eor\mvq)=pr(\mvp)+pr(\mvq)$
\end{description}

The first axiom tells us that there are no negative probability values. This is a contraint that mainly helps us to avoid certain mathematical frustration involving negative probabilities and the way that probabilities add and multiply together.

The second axiom says that if a sentence is a tautology, then we should assign a probability value of $1$ to that sentence.

Finally, the third axiom tells us that if two sentences are inconsistent, then the probability of either sentence is equal to the sum of the probabilities of each individual sentence.

\section{Universe}

As we've said, probabilities are defined over sentences. We can see how this works by considering some sentences about a simple situation: a coin flip. Suppose we have two sentences that we care about:
\begin{itemize}
  \item $P$ = ``The coin lands heads.''
  \item $Q$ = ``The coin lands tails.''
\end{itemize}
As should be clear, each of these sentences is the contrary of the other. So, $Q=\enot P$. We can apply probabilities to each of these sentences. $Pr(P)$ will take some value between $0$ and $1$, as will $\enot P$. Now, we ought to think that probabilities will interact in some way with our logical connectives. This is true, as we'll see soon, but before that let's just consider a few things about this situation.

First, each sentence in the collection of sentences that we care about will receive a probability. In order to be consistent, we should expect that the probabilities assigned to some of these sentences will constrain how other sentences will receive probabilities. This is, at least, because some sentences are a part of other sentence. For example, $(P\eand Q)$ and $P$, should interact or otherwise constrain one another. This is true of truth values as well, as we saw in the semantics chapters and sections of prior chapters.

Second, some of the sentences we care about may be related to one another but this isn't always clear from the logical formalism we use to represent them. Consider a six-sided die instead of a coin. The die has six faces and upon rolling the die it could land on 1, 2, 3, 4, 5, or 6. If we represent this with propositions $P$, $Q$, etc. we won't be able to distinguish the important logical relationship between them. However, doing so in propositional logic is unwieldy. Bear with me while I work through exactly why.

Consider the propositions ``The die lands on 1.'', ``The die lands on 2.'' etc. Represent these propositions as $P$, $Q$, $R$, $S$, $T$ and $U$. The following will be true in this interpretation:
\begin{itemize}
  \item $(P\eif(\enot Q \eand (\enot R \eand (\enot S \eand (\enot T \eand \enot U)))))$
  \item $(Q\eif(\enot P \eand (\enot R \eand (\enot S \eand (\enot T \eand \enot U)))))$
  \item $(R\eif(\enot P \eand (\enot Q \eand (\enot S \eand (\enot T \eand \enot U)))))$
  \item $(S\eif(\enot P \eand (\enot Q \eand (\enot R \eand (\enot T \eand \enot U)))))$
  \item $(T\eif(\enot P \eand (\enot Q \eand (\enot R \eand (\enot S \eand \enot U)))))$
  \item $(U\eif(\enot P \eand (\enot Q \eand (\enot R \eand (\enot S \eand \enot T)))))$
\end{itemize}
These are propositions that matter for what we should care about when describing the situation. But why? The reason is that these propositions are \emph{mutually exclusive}. That's also the situation that best describes the die itself. There's no way for the die to show multiple faces, so if it shows one of the faces then it won't show any of the others. Since we know these conditionals from the structure of the die itself we can infer the following:
\begin{itemize}
  \item $(P\eand(\enot Q \eand (\enot R \eand (\enot S \eand (\enot T \eand \enot U)))))$
  \item $(\enot P\eand(Q \eand (\enot R \eand (\enot S \eand (\enot T \eand \enot U)))))$
  \item $(\enot P\eand(\enot Q \eand (R \eand (\enot S \eand (\enot T \eand \enot U)))))$
  \item $(\enot P\eand(\enot Q \eand (\enot R \eand (S \eand (\enot T \eand \enot U)))))$
  \item $(\enot P\eand(\enot Q \eand (\enot R \eand (\enot S \eand (T \eand \enot U)))))$
  \item $(\enot P\eand(\enot Q \eand (\enot R \eand (\enot S \eand (\enot T \eand U)))))$
\end{itemize}
These sentences tell us more explicitly that each of these atomic propositions are mutually exclusive. Since each of the atomic propositions \emph{are} mutually exclusive, that should also inform us about how we should assign probabilities to these sentences.

The point of this exercise is twofold. First is that we know all these propositions from what we know about the structure of the die itself. If we didn't know anything about dice or how they work wouldn't know multiple faces couldn't appear at the same time then we would not be aware of these conditionals and so we would not be able to infer the extended conjunctions. Second, the probability assignments to the atomic sentences \emph{are not evident} from the representation of those sentences in propositional logic. In exactly the same way that certain natural language arguments fail to be valid when translated into propositional logic, the probabilistic connections between these propositions fails to be represented in this language as well.

OK, digression over. The point of this whole exercise is that we should care about how the sentences in our language get their probabilities assigned and that, in general, you can't just take a bunch of atomic propositions together and assign probabilities in any way you want and expect the relationships between those probabilities to reflect the underlying relationships between the sentences. So we should be careful.

One way we can represent this is by including some notation in our predicate logic that represents these relationships. For instance, consider six predicates $P_1,\ldots,P_6$ that are mutually inconsistent so that for each of the six predicates no object has more than one of these predicates. The trouble with this approach is that the `objects' are rolls of the die, which is an odd thing to treat as an object. It seems like the die itself is an object, not an individual roll.

Another way to represent this is by thinking of each roll as an `experiment' and to think of the experiments as the objects. This isn't very different from the earlier way of thinking, but to say that an experiment has its result as a property may strike you as less odd than thinking of a dice roll as having one.

For now, let's represent each experiment as a number $1$ through $6$ as shorthand. We can say that a die roll experiment gives a result $1$ through $6$ and that multiple trials of this experiment are strings of the numbers $1$ through $6$.

The ``population'' in statistical terms is a representation of all of the possible experiments. Another term for this is the ``universe.'' We will refer to the population or universe using the Greek capital letter omega: $\Omega$.

If we roll the die once, then $\Omega=\set{1,2,3,4,5,6}$. The size of this set depends on the experiment we are performing. In the case of the six-sided die, we can see that the size of $\Omega$ will grow exponentially ($6^N$, where N is the number of rolls) as we concern ourselves with additional rolls of the die.

How should we assign probabilities to the elements in $\Omega$? That is a very difficult question that continues to perplex philosophers and scientists alike. In short, there is no universal, objectively correct way to assign probabilities to elements in $\Omega$. The axioms of probability place some constraints on how events can be assigned, but within those constraints we can choose any assignment we like. We will see in the next chapter that we can always \emph{update} the probabilities we assign to the elements in $\Omega$ so maybe it is up to us to just pick any assignment we want.

Some philosophers have been unsatisfied with this response and how sought principles to help us assign probabilities in cases like this one. Pierre Simon Laplace%\marginfigure{\includegraphics[]{laplace}} 
was a French philosopher who proposed the following principle, now known as the Principle of Indifference. Here is what Laplace said:
\begin{quote}

\end{quote}
This principle tells us that when we don't know how to assign probabilities to a set of events, we should always distribute the probability equally over every event in the universe. In this case, each of our six possible outcomes will receive a probability of $\frac{1}{6}$, or $0.1\bar{6}$.

This principle is called the ``Principle of Indifference'' (sometimes called the Principle of Insufficient Reason) and while it is often employed to help us assign probabilities when we don't know how to do so, there are several reasons to doubt the truth of this principle. Many philosohpers have discussed the Principle of Indifference. [[Insert section on Bertrand's paradox, Keynes, etc. here.]]

One thing to point out here is that you may have already been thinking, ``Each face of a six-sided die is equally likely to show up, so we should assign each event the same probability!'' That is correct but notice something very important here; the reason for assigning probabilities that way is because we \emph{know something about how the die works.} In particular, we know that it was constructed specifically to have this property where each face is equally likely to appear. But what if we did not know this fact about dice? Or we had reason to think this die is different from other dice we've seen? Uncertainty of this kind is something that has plagued probability theory since its inception.

OK, let's take stock. If we are in a situation where we want to perform some experiment we can construct a population/universe called $\Omega$ that contains all of the possible outcomes of our experiment. If we don't know how to assign probabilities to these outcomes we can appeal to a principle like the Principle of Indifference to help us.

Now let's see some probabilities in action.

\section{Probability in Action}

Suppose we roll the die twice and want to know the probability of getting at least a $9$ when the rolls are added together. Our universe will be as follows:

$$\Omega = \set{11,12,13,14,15,16, 21,22,23,24,25,26, 31,32,33,34,35,36, 41,42,43,44,45,46, 51,52,53,54,55,56, 61,62,63,64,65,66}$$

If each of these events is assigned equal probability ($\frac{1}{36}$), then the probability that our dice rolls will sum to a $9$ or greater is:

$$Pr(36\lor 45\lor 46\lor 54\lor 55\lor 56\lor 63\lor 64\lor 65\lor 66)=Pr(36)+Pr(45)+Pr(46)+Pr(54)+Pr(55)+Pr(56)+Pr(63)+Pr(64)+Pr(65)+Pr(66)=\frac{10}{36}$$

Those are all the possible outcomes in which the die rolls sum to $9$ or greater, and because those events are mutually inconsistent we can simply add the probability of each to get our answer!
